{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNiaXODdcr4xsFD+Ak8SbSj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Use this file as a template to copy and build notebooks"],"metadata":{"id":"G3gcaM8YDQuA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeN_bD97C2O6"},"outputs":[],"source":["#@title Mount drive and load libraries\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","path = '/content/drive/MyDrive/msc-project-mbalmf01'\n","os.chdir(path)"]},{"cell_type":"code","source":["def get_aa_embedding(sequence: str, model: str, tokenizer, max_length: int):\n","  sequence = ' '.join(sequence)\n","  encoded_input = tokenizer(sequence, padding='max_length', return_tensors='pt')\n","  model_output = model(**encoded_input)\n","  return model_output.last_hidden_state\n","\n","device='cpu'\n","def aa_embeddings(seqs: list, model, tokenizer, max_length: int, device) -> list:\n","    seqs = [\" \".join(list(sequence)) for sequence in seqs]\n","    ids = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n","    input_ids = torch.tensor(ids['input_ids']).to(device)\n","    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n","    with torch.no_grad():\n","        embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask)\n","    ember = embedding_repr.last_hidden_state\n","    return ember\n","\n","seqs = df['sequence_alignment_aa_heavy'].to_list()\n","max_length = max([len(seq) for seq in seqs])\n","\n","seqs_chunked = chunks(seqs, len(seqs) // 500)\n","\n","for num, seq in enumerate(seqs_chunked):\n","  embeddings = [get_aa_embedding(s, model, tokenizer, max_length) for s in seq]\n","  embeddings = torch.cat(embeddings, dim=0)\n","  filepath = f\"/content/drive/MyDrive/msc-project-mbalmf01/embeddings/230814_ablang_H_aa_embeddings_{num}.pt\"\n","  torch.save(embeddings, filepath)\n","  del embeddings\n","  gc.collect()\n","\n","l = []\n","for j in os.listdir('/content/drive/MyDrive/msc-project-mbalmf01/embeddings/'):\n","  t = torch.load(f'/content/drive/MyDrive/msc-project-mbalmf01/embeddings/{j}')\n","  t = t.detach().numpy()\n","  l.append(t)\n","\n","ten = np.concatenate(l)\n","\n","!cp /content/array2.npy /content/drive/MyDrive/msc-project-mbalmf01/embeddings/array.npy"],"metadata":{"id":"wmn37m8gn9T0"},"execution_count":null,"outputs":[]}]}