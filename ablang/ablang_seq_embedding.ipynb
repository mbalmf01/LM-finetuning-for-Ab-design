{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUFzqHM/eTZBloyKjGqgBx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Embedding sequences using AbLang\n","\n","1.  Clone repo and install/import dependencies\n","2.  Read in sequences from MAPT file\n","3.  Load either heavy or light pretrained model\n","4.  Embed sequences and save to parquet"],"metadata":{"id":"jjP_-KKcAN-B"}},{"cell_type":"code","source":["#@title Clone repo\n","token = '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' #token specifically for reading and running code\n","username = ''\n","repo = 'msc-project-source-code-files-22-23-mbalmf01'\n","!git lfs install\n","!git clone https://{token}@github.com/Birkbeck/{repo}"],"metadata":{"id":"AEXRx76vjEYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7W6ddZtTg3cN","executionInfo":{"status":"ok","timestamp":1694809453117,"user_tz":-60,"elapsed":4087,"user":{"displayName":"Matt Balmforth","userId":"03166723450493542027"}},"outputId":"75a1622c-6eba-4ef7-cdee-46df40e24e1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'msc-project-source-code-files-22-23-mbalmf01'...\n","remote: Enumerating objects: 205, done.\u001b[K\n","remote: Counting objects: 100% (80/80), done.\u001b[K\n","remote: Compressing objects: 100% (67/67), done.\u001b[K\n","remote: Total 205 (delta 29), reused 56 (delta 13), pack-reused 125\u001b[K\n","Receiving objects: 100% (205/205), 87.57 MiB | 31.60 MiB/s, done.\n","Resolving deltas: 100% (85/85), done.\n"]}],"source":["# @title Clone repo for running project and install dependencies { display-mode: \"form\" }\n","%%capture\n","!pip3 install torch transformers\n","!python -m pip install ankh\n","\n","import sys\n","sys.path.append('/content/msc-project-source-code-files-22-23-mbalmf01/scripts')\n","import pandas as pd\n","from plm_manipulation import start_ablang, process_seqs, batch_embed"]},{"cell_type":"code","source":["#@title #####Load in sequences and MAPT scores\n","df = pd.read_parquet('/content/msc-project-source-code-files-22-23-mbalmf01/data_files/230816_aggpred_scores.parquet')"],"metadata":{"id":"BCxg9WjL_Znl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Load in model and tokenizer from Ablang Heavy model\n","model, tokenizer = start_ablang('AbLang_heavy')"],"metadata":{"id":"ySVPrWjOh1hV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Generate sequence embeddings for heavy and light chains using AbLang\n","tensor_df = batch_embed(df=df, prot_col='Model Seq H', seq_id='Filename', batch_size=100, model=model, tokenizer=tokenizer)\n","tensor_df.to_parquet('/content/msc-project-source-code-files-22-23-mbalmf01/data_files/ablang_H_embeddings.parquet')"],"metadata":{"id":"ljx1_D40hZst"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Load in AbLang light model, tokenizer and embed sequences\n","model, tokenizer = start_ablang('AbLang_light')\n","tensor_df = batch_embed(df=df, prot_col='Model Seq L', seq_id='Filename', batch_size=100, model=model, tokenizer=tokenizer)\n","tensor_df.to_parquet('/content/msc-project-source-code-files-22-23-mbalmf01/data_files/ablang_L_embeddings.parquet')"],"metadata":{"id":"NnBtWwsA_PQG"},"execution_count":null,"outputs":[]}]}